{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "034b041b-0347-4bf4-811a-1b27f5c5c50d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "7a_jyVYqZYAX"
      },
      "source": [
        "This notebook is for calculating distances, elevations and timings between Dovetrek checkpoints. It then produces a routecard for a set route.\n",
        "\n",
        "###Contents:\n",
        "* [Imports](#Imports)\n",
        "* [Start SparkSession](#Start-SparkSession)\n",
        "* [Set Parameters](#set-params)\n",
        "* [Get Secrets](#get-secrets)\n",
        "* [Fetch Checkpoint Information](#fetch-cp-info)\n",
        "* [Convert BNG to NGR](#bgn-to-ngr)\n",
        "* [Convert NGR to Latitude/Logitude](#ngr-to-latlong)\n",
        "* [Create Matrix of Checkpoint combinations](#cp-combos)\n",
        "* [Fetch Distances & Elevations from Google Maps API](#D&E-google)\n",
        "* [Fetch Distances & Elevations from OpenRouteService API](#D&E-ors)\n",
        "* [Fetch Distances & Elevations from Bing Maps API](#D&E-bing)\n",
        "* [Save Distances_DF as csv in memory](#)\n",
        "* [Upload Distances_DF csv to GitHub filestore](#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "974bdc0f-952f-42ad-998d-771f9c457da5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "QAc_bwqZZaGL"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "af05a933-18fa-48f8-8438-daecd4fe97c4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "YApO83OGZOji"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, expr, first\n",
        "from pyspark.sql import functions as F, DataFrame, Window, SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, FloatType, ArrayType, TimestampType\n",
        "from datetime import datetime, time, timedelta\n",
        "import requests\n",
        "import time\n",
        "import ipywidgets\n",
        "import base64\n",
        "import getpass\n",
        "import builtins\n",
        "import json\n",
        "from io import BytesIO, StringIO\n",
        "import itertools\n",
        "from functools import reduce\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "71915dae-0963-4246-a3ec-c43a31443c61",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "wa4P4R38ZiJB"
      },
      "source": [
        "### Start SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c561ed46-1f70-4e34-a340-5df2ff94f437",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "yx0kFjIVZOjl",
        "outputId": "b856fbb9-a908-45e6-f512-a594c924a3f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Alice|\n",
            "|  2|  Bob|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    SparkSession.active()\n",
        "except:\n",
        "    spark = SparkSession.builder \\\n",
        "        .appName(\"BinderPySpark\") \\\n",
        "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "        .getOrCreate()\n",
        "else:\n",
        "    SparkSession.active()\n",
        "finally:\n",
        "    # Test if Spark is working\n",
        "    df = spark.createDataFrame([(1, \"Alice\"), (2, \"Bob\")], [\"id\", \"name\"])\n",
        "    df.show()\n",
        "    df.unpersist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get available competition years"
      ],
      "metadata": {
        "id": "QRW-vup9wCWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = f\"https://api.github.com/repos/liamj-f/Dovetrek/contents/CheckpointData\"\n",
        "params = {\"ref\": \"main\"}\n",
        "response = requests.get(url, params=params)\n",
        "response.json()\n",
        "# Extract the 'name' field from each item in the JSON response\n",
        "Year_List = [item['name'] for item in response.json() if 'name' in item]\n",
        "\n",
        "# Extract the year using string slicing\n",
        "Year_List = [filename.split('_')[1].split('.')[0] for filename in Year_List]"
      ],
      "metadata": {
        "id": "qPmVV9GUtyY8"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1ed04aa7-1247-4b7d-b51c-00ddf52249db",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "BWoF_LmEZpMj"
      },
      "source": [
        "### Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4fa98d0e-d3ed-4eb5-9a4e-7c531fac5b79",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "referenced_widgets": [
            "0b975bc5ff2246d69c0556b839de514a",
            "9ff25a7170e045168e96940015e571b7",
            "77ecd564aa70409ca7db40953f03bc4b",
            "0210ab83af564a22aea4bad3e7dda24e",
            "86dfe68056b4498da1888947ef16543c",
            "de066c8b584d49cfbb0dd27138ec2986"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "0vovZWvDZOjn",
        "outputId": "fd286857-67a9-4589-a2ac-427c43b1fac7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Pick a competition year:', index=4, options=('2017', '2018', '2019', '2024', '2025'), va‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b975bc5ff2246d69c0556b839de514a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Pick an API Service for distance & elevations:', index=1, options=('Bing Maps', 'Google ‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0210ab83af564a22aea4bad3e7dda24e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Make sure all of the parameters are set correctly before entering your GitHub Secrets repository Personal Access Token below\n",
            "Token:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "API_Service_List = [\"Bing Maps\",\"Google Maps\", \"OpenRouteService\",\"Azure Maps & OpenTopoData\"]\n",
        "\n",
        "Competition_Year_Picker = ipywidgets.Dropdown(options=Year_List, value = '2025', description = 'Pick a competition year:')\n",
        "\n",
        "API_Service_Picker = ipywidgets.Dropdown(options=API_Service_List, value = \"Google Maps\", description = 'Pick an API Service for distance & elevations:')\n",
        "\n",
        "display(Competition_Year_Picker)\n",
        "display(API_Service_Picker)\n",
        "print(\"Make sure all of the parameters are set correctly before entering your GitHub Secrets repository Personal Access Token below\")\n",
        "GitHubPAT = getpass.getpass(\"Token:\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check parameters correctly set"
      ],
      "metadata": {
        "id": "GBjwIEsI9rYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(1)\n",
        "Competition_Year = Competition_Year_Picker.value\n",
        "API_Service = API_Service_Picker.value\n",
        "print(f\"Competition Year: {Competition_Year} \\nAPI Service: {API_Service}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgEdFbLe9gln",
        "outputId": "f7a9d864-8944-429b-d128-b6c3f127ee59"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Competition Year: 2019 \n",
            "API Service: Bing Maps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a3c45915-ce7b-4e0c-a784-4a009f3e5e3d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "lMkpnzqVZu6W"
      },
      "source": [
        "### Get Secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "660733c6-b8a4-4e17-9bb5-ba533297d8b0",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "UkBI5kXJZOjn",
        "outputId": "e0285e91-7d37-4449-bee0-052ad1929f67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Secrets loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# üîπ GitHub API URL to get the file\n",
        "url = f\"https://api.github.com/repos/liamj-f/Secrets/contents/Dovetrek_Secrets.json\"\n",
        "\n",
        "# üîπ GitHub API headers\n",
        "headers = {\"Authorization\": f\"token {GitHubPAT}\"}\n",
        "\n",
        "# üîπ Fetch the secrets file\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # Decode Base64 content\n",
        "    content = response.json()[\"content\"]\n",
        "    decoded_content = base64.b64decode(content).decode(\"utf-8\")\n",
        "\n",
        "    # Load JSON into a dictionary\n",
        "    secrets = json.loads(decoded_content)\n",
        "\n",
        "    # üîπ Assign values to variables\n",
        "    BingMapsAPIKey = secrets.get(\"BingMApsAPIKey\", \"\")\n",
        "    AzureMapsAPIKey = secrets.get(\"AzureMapsAPIKey\", \"\")\n",
        "    OrdnanceSurveyAPIKey = secrets.get(\"OrdnanceSurveyAPIKey\", \"\")\n",
        "    OpenRouteServiceAPIKey = secrets.get(\"OpenRouteServiceAPIKey\", \"\")\n",
        "    GoogleMapsAPIKey = secrets.get(\"GoogleMapsAPIKey\", \"\")\n",
        "    DovetrekRepoPAT = secrets.get(\"DovetrekRepoPAT\", \"\")\n",
        "\n",
        "    print(\"‚úÖ Secrets loaded successfully!\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå Error: {response.status_code} - {response.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "316cf1e3-a2c3-42b4-b086-5b3001d30c31",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "n5Ey-Z8caLSx"
      },
      "source": [
        "### Fetch Checkpoint information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c89cd91e-5df2-4de3-9adb-a2030859bfe6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ntc4Wr6rZOjo"
      },
      "outputs": [],
      "source": [
        "# GitHub API URL for file content\n",
        "url = f\"https://api.github.com/repos/liamj-f/Dovetrek/contents/CheckpointData/Openings_{Competition_Year}.csv\"\n",
        "\n",
        "# Fetch file content\n",
        "response = requests.get(url, headers=headers)\n",
        "content = response.json()[\"content\"]\n",
        "decoded_content = base64.b64decode(content).decode(\"utf-8\")\n",
        "csv_lines = decoded_content.split(\"\\n\")\n",
        "# Create an RDD from the list\n",
        "rdd = spark.sparkContext.parallelize(csv_lines)\n",
        "# Convert RDD to DataFrame\n",
        "openings_df = spark.read.csv(rdd, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a9c33657-5a5d-4800-9693-7f7ee11b225f",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "HhoozVryaNzW"
      },
      "source": [
        "### Convert BNG to NGR\n",
        "The actual grid square identifiers are missing from the datasets because Dovetrek always takes place in the same area, so conversion from letter to number not necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4402ee60-5261-4d6f-a282-7fe82bdaefd6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "3HmzSfT4ZOjo",
        "outputId": "34df37ca-de10-43f6-e23f-680f39933fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[CP: string, BNG: string, 1000: int, 1030: int, 1100: int, 1130: int, 1200: int, 1230: int, 1300: int, 1330: int, 1400: int, 1430: int, 1500: int, 1530: int, 1600: int, 1630: int, 1700\n",
              ": double, NGR_Easting: double, NGR_Northing: double]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "openings_df = openings_df.withColumn(\"NGR_Easting\", F.concat(F.lit(\"4\"), F.substring(openings_df.BNG, 1, 3), F.lit(\"00\")).cast(\"double\")) \\\n",
        "                    .withColumn(\"NGR_Northing\", F.concat(F.lit(\"3\"), F.substring(openings_df.BNG, 5, 3), F.lit(\"00\")).cast(\"double\"))\n",
        "display(openings_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "daec1bf4-ee9e-4f71-a767-faf0b5ded0ad",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "RIuBgBkJaS1G"
      },
      "source": [
        "### Convert NGR to Latitude/Longitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8b98be36-e1f3-427d-a67a-6c50e03823b6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "xLDpXR5eZOjp",
        "outputId": "9c66937b-6d6a-4df1-d4c8-12e4ef072df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[CP: string, BNG: string, 1000: int, 1030: int, 1100: int, 1130: int, 1200: int, 1230: int, 1300: int, 1330: int, 1400: int, 1430: int, 1500: int, 1530: int, 1600: int, 1630: int, 1700\n",
              ": double, NGR_Easting: double, NGR_Northing: double, Latitude: float, Longitude: float]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "LatLong_Df = spark.createDataFrame(\n",
        "    [(1, 1.0, 1.0)],\n",
        "    schema='CP string, Latitude float, Longitude float'\n",
        ")\n",
        "LatLong_Df = LatLong_Df.filter('1!=1')\n",
        "\n",
        "# Convert DataFrame to a list\n",
        "gridrefs_list = openings_df.select(\n",
        "    openings_df.CP,\n",
        "    openings_df.NGR_Easting,\n",
        "    openings_df.NGR_Northing\n",
        ").collect()\n",
        "\n",
        "# Iterate over the list\n",
        "for row in gridrefs_list:\n",
        "    # Perform desired operations with the column values\n",
        "    resp = requests.get(\n",
        "        \"http://webapps.bgs.ac.uk/data/webservices/CoordConvert_LL_BNG.cfc?method=BNGtoLatLng&easting=\"\n",
        "        + str(row.NGR_Easting)\n",
        "        + \"&northing=\"\n",
        "        + str(row.NGR_Northing)\n",
        "    )\n",
        "\n",
        "    # Parse the JSON response\n",
        "    json_resp = json.loads(resp.text)\n",
        "\n",
        "    # Check if 'LATITUDE' and 'LONGITUDE' keys exist in the response\n",
        "    if 'LATITUDE' in json_resp and 'LONGITUDE' in json_resp:\n",
        "        # Extract latitude and longitude values\n",
        "        latitude = json_resp['LATITUDE']\n",
        "        longitude = json_resp['LONGITUDE']\n",
        "        cp = row[\"CP\"]\n",
        "\n",
        "        df = spark.createDataFrame(\n",
        "            [(cp, latitude, longitude)],\n",
        "            'CP string, Latitude float, Longitude float'\n",
        "        )\n",
        "        LatLong_Df = LatLong_Df.union(df)\n",
        "\n",
        "openings_df = openings_df.join(LatLong_Df, openings_df.CP == LatLong_Df.CP).drop(LatLong_Df.CP)\n",
        "\n",
        "LatLong_Df.unpersist()\n",
        "# Show DataFrame\n",
        "display(openings_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8e8f8214-b37e-4902-a301-1bef3bd6b686",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "rzH9dfeBaUw_"
      },
      "source": [
        "### Create Matrix of Checkpoint combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c5e965e0-fc57-4ba2-8a51-903621f984ea",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "XHj6f09TZOjp",
        "outputId": "d63637a6-fe5d-467d-e67d-5eb73d89f188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[StartCP: string, FinishCP: string, StartLatitude: float, StartLongitude: float, FinishLatitude: float, FinishLongitude: float]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# So this isn't the best way to do this, i realise, but it is reused code from another part of the project and doesn't take too long so we may as well just get every combination and run it through the api\n",
        "\n",
        "StartCPs = openings_df.select(\"CP\").withColumnRenamed(\"CP\",\"StartCP\")\n",
        "FinishCPs = openings_df.select(\"CP\").withColumnRenamed(\"CP\",\"FinishCP\")\n",
        "CP_Combinations_DF = StartCPs.crossJoin(FinishCPs)\n",
        "\n",
        "StartCPs.unpersist\n",
        "FinishCPs.unpersist\n",
        "\n",
        "CP_Combinations_DF = CP_Combinations_DF.alias(\"df\").join(openings_df.select(\"CP\", \"Latitude\", \"Longitude\").withColumnRenamed('Latitude','StartLatitude').withColumnRenamed('Longitude','StartLongitude'), CP_Combinations_DF.StartCP == openings_df.CP).drop(\"CP\")\n",
        "\n",
        "CP_Combinations_DF = CP_Combinations_DF.alias(\"df\").join(openings_df.select(\"CP\", \"Latitude\", \"Longitude\").withColumnRenamed('Latitude','FinishLatitude').withColumnRenamed('Longitude','FinishLongitude'), CP_Combinations_DF.FinishCP == openings_df.CP).drop(\"CP\")\n",
        "\n",
        "CP_Combinations_DF = CP_Combinations_DF.filter(CP_Combinations_DF.StartCP != CP_Combinations_DF.FinishCP)\n",
        "display(CP_Combinations_DF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d89816f9-c35d-4b50-a6a7-472a390cf875",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "gDmfNLF2ahSL"
      },
      "source": [
        "### Fetch Distances & Elevations from Google Maps API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "30283d9b-8cc2-48c9-add1-6d46f231ec1c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "CijR4BV7ZOjp",
        "outputId": "564c75b1-98f9-45de-85a2-a2cf0d365f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping Google Maps Cell, selected service: OpenRouteService\n"
          ]
        }
      ],
      "source": [
        "if API_Service == \"Google Maps\":\n",
        "\n",
        "  CP_Combinations_List = CP_Combinations_DF.collect()\n",
        "\n",
        "  Distances_DF = spark.createDataFrame(\n",
        "      [(1, 1.0, 1.0, 1)],\n",
        "      schema='StartCP string, FinishCP string, Distance float, Height_Gain int'\n",
        "  )\n",
        "  Distances_DF = Distances_DF.filter(\"1!=1\")\n",
        "\n",
        "  def make_request(method, url, **kwargs):\n",
        "      \"\"\"Helper function to handle API requests with 429 retry logic.\"\"\"\n",
        "      while True:\n",
        "          response = requests.request(method, url, **kwargs)\n",
        "          if response.status_code == 429:\n",
        "              print(\"Rate limit exceeded (429). Waiting 60 seconds before retrying...\")\n",
        "              time.sleep(60)\n",
        "          else:\n",
        "              return response  # Return response if successful\n",
        "\n",
        "  for row in CP_Combinations_List:\n",
        "      wp1 = f\"{row.StartLongitude},{row.StartLatitude}\"\n",
        "      wp2 = f\"{row.FinishLongitude},{row.FinishLatitude}\"\n",
        "\n",
        "      # Route API Call with Retry Handling\n",
        "      route_url = \"https://routes.googleapis.com/directions/v2:computeRoutes\"\n",
        "      route_params = {\n",
        "    \"origin\":{\n",
        "      \"location\":{\n",
        "        \"latLng\":{\n",
        "          \"latitude\": row.StartLatitude,\n",
        "          \"longitude\": row.StartLongitude\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"destination\":{\n",
        "      \"location\":{\n",
        "        \"latLng\":{\n",
        "          \"latitude\": row.FinishLatitude,\n",
        "          \"longitude\": row.FinishLongitude\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"travelMode\": \"WALK\",\n",
        "    \"languageCode\": \"en-GB\",\n",
        "    \"units\": \"METRIC\"\n",
        "  }\n",
        "      route_headers = {\n",
        "          \"X-Goog-Api-Key\": GoogleMapsAPIKey,\n",
        "          \"X-Goog-FieldMask\": \"routes.duration,routes.distanceMeters,routes.polyline,routes.legs\"\n",
        "      }\n",
        "\n",
        "      route_resp = make_request(\"POST\", route_url, headers=route_headers, json=route_params)\n",
        "      route_json_resp = route_resp.json()\n",
        "\n",
        "      travel_distance = float(route_json_resp[\"routes\"][0][\"legs\"][0][\"distanceMeters\"]) / 1000\n",
        "      StartCP, FinishCP = row[\"StartCP\"], row[\"FinishCP\"]\n",
        "\n",
        "      # Prepare height points for elevation request\n",
        "      height_polyline = route_json_resp[\"routes\"][0][\"polyline\"][\"encodedPolyline\"]\n",
        "\n",
        "\n",
        "      # Elevation API Call with Retry Handling\n",
        "      elevations_url = \"https://maps.googleapis.com/maps/api/elevation/json\"\n",
        "      elevations_params = {\n",
        "          \"path\": \"enc:\"+height_polyline,\n",
        "          \"samples\": 100,\n",
        "          \"key\": GoogleMapsAPIKey\n",
        "      }\n",
        "\n",
        "      elevations_resp = make_request(\"GET\", elevations_url, params=elevations_params)\n",
        "      elevation_json_resp = elevations_resp.json()\n",
        "      elevations = [point[\"elevation\"] for point in elevation_json_resp[\"results\"]]\n",
        "      differences = [builtins.max(0, elevations[i+1] - elevations[i]) for i in range(len(elevations)-1)]\n",
        "      height_gain = float(sum(differences))\n",
        "\n",
        "      # Append to Spark DataFrame\n",
        "      df = spark.createDataFrame(\n",
        "          [(StartCP, FinishCP, travel_distance, height_gain)],\n",
        "          'StartCP string, FinishCP string, Distance float, Height_Gain float'\n",
        "      )\n",
        "      Distances_DF = Distances_DF.union(df)\n",
        "\n",
        "  #   time.sleep(2.0)  # Keep a delay between requests to reduce rate limits\n",
        "\n",
        "  display(Distances_DF)\n",
        "\n",
        "else:\n",
        "    print(f\"Skipping Google Maps Cell, selected service: {API_Service}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "95e86e26-53ba-4586-975f-c687702d967c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Nm5X7PahDxOP"
      },
      "source": [
        "### Fetch Distances & Elevations from Azure Maps and OpenTopoData APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f7828cd5-89b9-4f71-b685-f83d83287c86",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "-99WdniFDwHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e0e4d1-1f1b-47b5-e9eb-2392b5f2d21f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping Azure Maps Cell, selected service: OpenRouteService\n"
          ]
        }
      ],
      "source": [
        "# Takes ~17 minutes due to OpenTopoData API limits 1 per second\n",
        "if API_Service == \"Azure Maps & OpenTopoData\":\n",
        "\n",
        "    CP_Combinations_List = CP_Combinations_DF.collect()\n",
        "\n",
        "    Distances_DF = spark.createDataFrame(\n",
        "        [(1, 1.0, 1.0, 1)],\n",
        "        schema='StartCP string, FinishCP string, Distance float, Height_Gain int'\n",
        "    )\n",
        "    Distances_DF = Distances_DF.filter(\"1!=1\")\n",
        "\n",
        "    MAX_LOCATIONS = 100  # OpenTopoData API limit\n",
        "\n",
        "    for row in CP_Combinations_List:\n",
        "        wp1 = f\"{row.StartLatitude},{row.StartLongitude}\"\n",
        "        wp2 = f\"{row.FinishLatitude},{row.FinishLongitude}\"\n",
        "\n",
        "        # Azure Maps Routing API\n",
        "        route_url = \"https://atlas.microsoft.com/route/directions/json\"\n",
        "        route_params = {\n",
        "            \"subscription-key\": AzureMapsAPIKey,\n",
        "            \"api-version\": \"1.0\",\n",
        "            \"query\": f\"{wp1}:{wp2}\",\n",
        "            \"travelMode\": \"pedestrian\",\n",
        "            \"routeType\": \"shortest\",\n",
        "            \"traffic\": \"false\",\n",
        "            \"computeBestOrder\": \"false\",\n",
        "            \"computeTravelTimeFor\": \"all\",\n",
        "        }\n",
        "        route_resp = requests.get(route_url, params=route_params)\n",
        "        route_json_resp = json.loads(route_resp.text)\n",
        "\n",
        "        travel_distance = float(route_json_resp['routes'][0]['summary']['lengthInMeters']) / 1000  # Convert meters to km\n",
        "        StartCP = row[\"StartCP\"]\n",
        "        FinishCP = row[\"FinishCP\"]\n",
        "\n",
        "        # Extract route coordinates\n",
        "        height_points = route_json_resp['routes'][0]['legs'][0]['points']\n",
        "        coordinates = [f\"{pt['latitude']},{pt['longitude']}\" for pt in height_points]\n",
        "\n",
        "        # Batch coordinates into chunks of 100\n",
        "        elevation_results = []\n",
        "        for i in range(0, len(coordinates), MAX_LOCATIONS):\n",
        "            chunk = \"|\".join(coordinates[i:i + MAX_LOCATIONS])  # Format chunk\n",
        "\n",
        "            # OpenTopoData API call\n",
        "            opentopo_url = \"https://api.opentopodata.org/v1/eudem25m\"  # Example dataset\n",
        "            opentopo_params = {\"locations\": chunk}\n",
        "            elevations_resp = requests.get(opentopo_url, params=opentopo_params)\n",
        "            elevations_json_resp = json.loads(elevations_resp.text)\n",
        "\n",
        "            # Extract elevations\n",
        "            if 'results' in elevations_json_resp:\n",
        "                elevation_results.extend([result['elevation'] for result in elevations_json_resp['results']])\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "        # Calculate height gain\n",
        "        differences = [max(0, elevation_results[i+1] - elevation_results[i]) for i in range(len(elevation_results)-1)]\n",
        "        height_gain = float(sum(differences))\n",
        "\n",
        "        df = spark.createDataFrame(\n",
        "            [(StartCP, FinishCP, travel_distance, height_gain)],\n",
        "            'StartCP string, FinishCP string, Distance float, Height_Gain float'\n",
        "        )\n",
        "        Distances_DF = Distances_DF.union(df)\n",
        "\n",
        "    display(Distances_DF)\n",
        "\n",
        "else:\n",
        "    print(f\"Skipping Azure Maps Cell, selected service: {API_Service}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d0aa6010-cebe-41e4-93a2-0bc7121af680",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "hEiYF_NZa0DX"
      },
      "source": [
        "### Fetch Distances & Elevations from OpenRouteService API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "db3c134e-3e16-4d50-bc85-5faa2b84dac8",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "IBg4evZ5ZOjq",
        "outputId": "28b455dc-1b23-4006-f0b5-03e7b596d96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "PySparkTypeError",
          "evalue": "[CANNOT_ACCEPT_OBJECT_IN_TYPE] `FloatType()` can not accept object `0` in type `int`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-2955e5270c5e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Append to Spark DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         df = spark.createDataFrame(\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStartCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFinishCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtravel_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_gain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;34m'StartCP string, FinishCP string, Distance float, Height_Gain float'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             )\n\u001b[0;32m-> 1443\u001b[0;31m         return self._create_dataframe(\n\u001b[0m\u001b[1;32m   1444\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1483\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# make sure data could consumed multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mno_type_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m                 \u001b[0mverify_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mverify_nullability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m             \u001b[0mverify_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_struct\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2172\u001b[0m                     )\n\u001b[1;32m   2173\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2174\u001b[0;31m                     \u001b[0mverifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2175\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dict__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mverify_nullability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m             \u001b[0mverify_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_default\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2193\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mverify_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m             \u001b[0massert_acceptable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2195\u001b[0;31m             \u001b[0mverify_acceptable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0mverify_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_acceptable_types\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0;31m# subclass of them can not be fromInternal in JVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_acceptable_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2020\u001b[0;31m             raise PySparkTypeError(\n\u001b[0m\u001b[1;32m   2021\u001b[0m                 \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CANNOT_ACCEPT_OBJECT_IN_TYPE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m                 message_parameters={\n",
            "\u001b[0;31mPySparkTypeError\u001b[0m: [CANNOT_ACCEPT_OBJECT_IN_TYPE] `FloatType()` can not accept object `0` in type `int`."
          ]
        }
      ],
      "source": [
        "if API_Service == \"OpenRouteService\":\n",
        "\n",
        "    CP_Combinations_List = CP_Combinations_DF.collect()\n",
        "\n",
        "    Distances_DF = spark.createDataFrame(\n",
        "        [(1, 1.0, 1.0, 1)],\n",
        "        schema='StartCP string, FinishCP string, Distance float, Height_Gain int'\n",
        "    )\n",
        "    Distances_DF = Distances_DF.filter(\"1!=1\")\n",
        "\n",
        "    def make_request(method, url, **kwargs):\n",
        "        \"\"\"Helper function to handle API requests with 429 retry logic.\"\"\"\n",
        "        while True:\n",
        "            response = requests.request(method, url, **kwargs)\n",
        "            if response.status_code == 429:\n",
        "                print(\"Rate limit exceeded (429). Waiting 60 seconds before retrying...\")\n",
        "                time.sleep(60)\n",
        "            else:\n",
        "                return response  # Return response if successful\n",
        "\n",
        "    for row in CP_Combinations_List:\n",
        "        wp1 = f\"{row.StartLongitude},{row.StartLatitude}\"\n",
        "        wp2 = f\"{row.FinishLongitude},{row.FinishLatitude}\"\n",
        "\n",
        "        # Route API Call with Retry Handling\n",
        "        route_url = \"https://api.openrouteservice.org/v2/directions/foot-hiking\"\n",
        "        route_params = {\n",
        "            \"start\": wp1,\n",
        "            \"end\": wp2,\n",
        "            \"api_key\": OpenRouteServiceAPIKey\n",
        "        }\n",
        "        route_resp = make_request(\"GET\", route_url, params=route_params)\n",
        "        route_json_resp = route_resp.json()\n",
        "\n",
        "        travel_distance = float(route_json_resp[\"features\"][0][\"properties\"][\"summary\"][\"distance\"]) / 1000\n",
        "        StartCP, FinishCP = row[\"StartCP\"], row[\"FinishCP\"]\n",
        "\n",
        "        # Prepare height points for elevation request\n",
        "        height_points = route_json_resp[\"features\"][0][\"geometry\"][\"coordinates\"]\n",
        "        flattened_height_points = \",\".join([f\"{lon},{lat}\" for lon, lat in height_points])\n",
        "\n",
        "        # Elevation API Call with Retry Handling\n",
        "        elevations_url = \"https://api.openrouteservice.org/elevation/line\"\n",
        "        elevations_params = {\n",
        "            \"format_in\": \"polyline\",\n",
        "            \"format_out\": \"polyline\",\n",
        "            \"dataset\": \"srtm\",\n",
        "            \"geometry\": height_points\n",
        "        }\n",
        "        elevations_headers = {\n",
        "            \"Authorization\": OpenRouteServiceAPIKey,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        elevations_resp = make_request(\"POST\", elevations_url, headers=elevations_headers, json=elevations_params)\n",
        "        elevation_json_resp = elevations_resp.json()\n",
        "        elevation_coordinates = elevation_json_resp[\"geometry\"]\n",
        "        elevations = [elev for _, _, elev in elevation_coordinates]\n",
        "        differences = [builtins.max(0, elevations[i+1] - elevations[i]) for i in range(len(elevations)-1)]\n",
        "        height_gain = float(sum(differences))\n",
        "\n",
        "        # Append to Spark DataFrame\n",
        "        df = spark.createDataFrame(\n",
        "            [(StartCP, FinishCP, travel_distance, height_gain)],\n",
        "            'StartCP string, FinishCP string, Distance float, Height_Gain float'\n",
        "        )\n",
        "        Distances_DF = Distances_DF.union(df)\n",
        "\n",
        "        time.sleep(2.0)  # Keep a delay between requests to reduce rate limits\n",
        "\n",
        "    display(Distances_DF)\n",
        "\n",
        "else:\n",
        "    print(f\"Skipping OpenRouteService Cell, selected service: {API_Service}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8a5d2b85-ede0-4853-91d8-409962eceee4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "KTNhw6YTa5I2"
      },
      "source": [
        "### Fetch Distances & Elevations from Bing Maps API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "157932ad-5f46-409f-b9cb-08e5a8f8b199",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "G4qfCSi8ZOjq"
      },
      "outputs": [],
      "source": [
        "if API_Service == \"Bing Maps\":\n",
        "\n",
        "    CP_Combinations_List = CP_Combinations_DF.collect()\n",
        "\n",
        "    Distances_DF = spark.createDataFrame(\n",
        "        [(1, 1.0, 1.0, 1)],\n",
        "        schema='StartCP string, FinishCP string, Distance float, Height_Gain int'\n",
        "    )\n",
        "    Distances_DF = Distances_DF.filter(\"1!=1\")\n",
        "\n",
        "    for row in CP_Combinations_List:\n",
        "        wp1 = str(row.StartLatitude) + ',' + str(row.StartLongitude)\n",
        "        wp2 = str(row.FinishLatitude) + ',' + str(row.FinishLongitude)\n",
        "\n",
        "        route_url = \"http://dev.virtualearth.net/REST/v1/Routes/walking\"\n",
        "        route_params = {\n",
        "            \"wayPoint.1\": wp1,\n",
        "            \"waypoint.2\": wp2,\n",
        "            \"optimize\": \"distance\",\n",
        "            \"avoid\": \"ferry\",\n",
        "            \"routeAttributes\": \"routePath,excludeItinerary\",\n",
        "            \"distanceUnit\": \"km\",\n",
        "            \"key\": BingMapsAPIKey\n",
        "        }\n",
        "        route_resp = requests.get(route_url, params=route_params)\n",
        "        route_json_resp = json.loads(route_resp.text)\n",
        "        travel_distance = float(route_json_resp['resourceSets'][0]['resources'][0]['travelDistance'])\n",
        "        StartCP = row[\"StartCP\"]\n",
        "        FinishCP = row[\"FinishCP\"]\n",
        "\n",
        "        height_points = route_json_resp['resourceSets'][0]['resources'][0]['routePath']['line']['coordinates']\n",
        "        flattened_height_points = \",\".join([f\"{lat},{lon}\" for lat, lon in height_points])  # Fix formatting\n",
        "\n",
        "        elevations_url = \"http://dev.virtualearth.net/REST/v1/Elevation/List\"\n",
        "        elevations_params = {\n",
        "            \"points\": flattened_height_points,\n",
        "            \"heights\": \"ellipsoid\",\n",
        "            \"key\": BingMapsAPIKey\n",
        "        }\n",
        "        elevations_resp = requests.get(elevations_url, params=elevations_params)\n",
        "        elevations_json_resp = json.loads(elevations_resp.text)\n",
        "        elevations = elevations_json_resp['resourceSets'][0]['resources'][0]['elevations']\n",
        "        differences = [builtins.max(0, elevations[i+1] - elevations[i]) for i in range(len(elevations)-1)]\n",
        "        height_gain = float(sum(differences))\n",
        "\n",
        "        df = spark.createDataFrame(\n",
        "            [(StartCP, FinishCP, travel_distance, height_gain)],\n",
        "            'StartCP string, FinishCP string, Distance float, Height_Gain int'\n",
        "        )\n",
        "        Distances_DF = Distances_DF.union(df)\n",
        "\n",
        "    display(Distances_DF)\n",
        "\n",
        "else:\n",
        "    print(f\"Skipping BingMaps Cell, selected service: {API_Service}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8b04d483-5e90-491b-8e64-a2388295b727",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "bC5vW2tvqo2z"
      },
      "source": [
        "### Fetch Distances & Elevations from Azure Maps & OpenTopoData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "67bb3a3a-191e-49b1-9de7-d6038c2fbed5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "3gp0GRdZqo2z"
      },
      "outputs": [],
      "source": [
        "# Takes ~17 minutes due to OpenTopoData API limits 1 per second\n",
        "if API_Service == \"Azure Maps & OpenTopoData\":\n",
        "\n",
        "    CP_Combinations_List = CP_Combinations_DF.collect()\n",
        "\n",
        "    Distances_DF = spark.createDataFrame(\n",
        "        [(1, 1.0, 1.0, 1)],\n",
        "        schema='StartCP string, FinishCP string, Distance float, Height_Gain int'\n",
        "    )\n",
        "    Distances_DF = Distances_DF.filter(\"1!=1\")\n",
        "\n",
        "    MAX_LOCATIONS = 100  # OpenTopoData API limit\n",
        "\n",
        "    for row in CP_Combinations_List:\n",
        "        wp1 = f\"{row.StartLatitude},{row.StartLongitude}\"\n",
        "        wp2 = f\"{row.FinishLatitude},{row.FinishLongitude}\"\n",
        "\n",
        "        # Azure Maps Routing API\n",
        "        route_url = \"https://atlas.microsoft.com/route/directions/json\"\n",
        "        route_params = {\n",
        "            \"subscription-key\": AzureMapsAPIKey,\n",
        "            \"api-version\": \"1.0\",\n",
        "            \"query\": f\"{wp1}:{wp2}\",\n",
        "            \"travelMode\": \"pedestrian\",\n",
        "            \"routeType\": \"shortest\",\n",
        "            \"traffic\": \"false\",\n",
        "            \"computeBestOrder\": \"false\",\n",
        "            \"computeTravelTimeFor\": \"all\",\n",
        "        }\n",
        "        route_resp = requests.get(route_url, params=route_params)\n",
        "        route_json_resp = json.loads(route_resp.text)\n",
        "\n",
        "        travel_distance = float(route_json_resp['routes'][0]['summary']['lengthInMeters']) / 1000  # Convert meters to km\n",
        "        StartCP = row[\"StartCP\"]\n",
        "        FinishCP = row[\"FinishCP\"]\n",
        "\n",
        "        # Extract route coordinates\n",
        "        height_points = route_json_resp['routes'][0]['legs'][0]['points']\n",
        "        coordinates = [f\"{pt['latitude']},{pt['longitude']}\" for pt in height_points]\n",
        "\n",
        "        # Batch coordinates into chunks of 100\n",
        "        elevation_results = []\n",
        "        for i in range(0, len(coordinates), MAX_LOCATIONS):\n",
        "            chunk = \"|\".join(coordinates[i:i + MAX_LOCATIONS])  # Format chunk\n",
        "\n",
        "            # OpenTopoData API call\n",
        "            opentopo_url = \"https://api.opentopodata.org/v1/eudem25m\"  # Example dataset\n",
        "            opentopo_params = {\"locations\": chunk}\n",
        "            elevations_resp = requests.get(opentopo_url, params=opentopo_params)\n",
        "            elevations_json_resp = json.loads(elevations_resp.text)\n",
        "\n",
        "            # Extract elevations\n",
        "            if 'results' in elevations_json_resp:\n",
        "                elevation_results.extend([result['elevation'] for result in elevations_json_resp['results']])\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "        # Calculate height gain\n",
        "        differences = [max(0, elevation_results[i+1] - elevation_results[i]) for i in range(len(elevation_results)-1)]\n",
        "        height_gain = float(sum(differences))\n",
        "\n",
        "        df = spark.createDataFrame(\n",
        "            [(StartCP, FinishCP, travel_distance, height_gain)],\n",
        "            'StartCP string, FinishCP string, Distance float, Height_Gain float'\n",
        "        )\n",
        "        Distances_DF = Distances_DF.union(df)\n",
        "\n",
        "    display(Distances_DF)\n",
        "\n",
        "else:\n",
        "    print(f\"Skipping Azure Maps Cell, selected service: {API_Service}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "eaf113fa-2ca9-45fb-bda2-0d6785c2bdcd",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "hep6o1SxH3q3"
      },
      "source": [
        "### Save Distances_DF as csv in memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0892570f-6d04-4ab3-a298-0c96ca30a84a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "3aSO3PBKH1K4"
      },
      "outputs": [],
      "source": [
        "# üîπ Save image to an in-memory buffer\n",
        "buf = BytesIO()\n",
        "Distances_DF.toPandas().to_csv(buf, index=False)\n",
        "buf.seek(0)  # Move to start of buffer\n",
        "\n",
        "# üîπ Convert buffer to Base64\n",
        "encoded_content = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
        "\n",
        "filename = f\"Distances_DF_{Competition_Year}_{API_Service}_{datetime.today().date()}.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d5435621-b167-466b-8e7b-3c1494332e2d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "oMV1YQAeH8-F"
      },
      "source": [
        "### Upload Distances_DF csv to GitHub filestore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d78d845d-183c-4361-8c3b-0dfe82f02b62",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "X9QXGu2xH8p8"
      },
      "outputs": [],
      "source": [
        "# üîπ GitHub API URL\n",
        "url = f\"https://api.github.com/repos/liamj-f/Dovetrek/contents/DataFrames/{filename}\"\n",
        "\n",
        "# Get the latest SHA (if the file exists)\n",
        "response = requests.get(url, headers={\"Authorization\": f\"token {DovetrekRepoPAT}\"})\n",
        "sha = response.json().get(\"sha\") if response.status_code == 200 else None\n",
        "\n",
        "# üîπ Upload file to GitHub\n",
        "payload = {\n",
        "    \"message\": f\"Auto-upload {filename} from notebook run\",\n",
        "    \"content\": encoded_content,\n",
        "    \"branch\": \"FileStore\"\n",
        "}\n",
        "if sha:\n",
        "    payload[\"sha\"] = sha  # Required if updating an existing file\n",
        "\n",
        "response = requests.put(url, headers={\"Authorization\": f\"token {DovetrekRepoPAT}\"}, json=payload)\n",
        "\n",
        "if response.status_code in [200, 201]:\n",
        "    print(f\"‚úÖ {filename} uploaded successfully to Dovetrek/DataFrames (Filestore branch)!\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: {response.status_code} - {response.text}\")"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "environment_version": "2"
      },
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2,
        "widgetLayout": [
          {
            "breakBefore": false,
            "name": "API_Service",
            "width": 190
          },
          {
            "breakBefore": false,
            "name": "Competition_Year",
            "width": 190
          },
          {
            "breakBefore": false,
            "name": "Dwell",
            "width": 190
          },
          {
            "breakBefore": false,
            "name": "Naismith",
            "width": 190
          },
          {
            "breakBefore": false,
            "name": "Speed",
            "width": 190
          }
        ]
      },
      "notebookName": "Dovetrek Distances Calculator",
      "widgets": {
        "API_Service": {
          "currentValue": "Bing Maps",
          "nuid": "4af94965-bf6a-4581-9869-4c3791367508",
          "typedWidgetInfo": {
            "autoCreated": false,
            "defaultValue": "Google Maps",
            "label": null,
            "name": "API_Service",
            "options": {
              "widgetDisplayType": "Dropdown",
              "choices": [
                "Bing Maps",
                "Google Maps",
                "OpenRouteService",
                "Azure Maps & OpenTopoData"
              ],
              "fixedDomain": true,
              "multiselect": false
            },
            "parameterDataType": "String"
          },
          "widgetInfo": {
            "widgetType": "dropdown",
            "defaultValue": "Google Maps",
            "label": null,
            "name": "API_Service",
            "options": {
              "widgetType": "dropdown",
              "autoCreated": null,
              "choices": [
                "Bing Maps",
                "Google Maps",
                "OpenRouteService",
                "Azure Maps & OpenTopoData"
              ]
            }
          }
        },
        "Competition_Year": {
          "currentValue": "2025",
          "nuid": "fa25c94e-f505-4fec-9214-3aa56df90164",
          "typedWidgetInfo": {
            "autoCreated": false,
            "defaultValue": "2025",
            "label": null,
            "name": "Competition_Year",
            "options": {
              "widgetDisplayType": "Dropdown",
              "choices": [
                "2025",
                "2024",
                "2019",
                "2018",
                "2017"
              ],
              "fixedDomain": true,
              "multiselect": false
            },
            "parameterDataType": "String"
          },
          "widgetInfo": {
            "widgetType": "dropdown",
            "defaultValue": "2025",
            "label": null,
            "name": "Competition_Year",
            "options": {
              "widgetType": "dropdown",
              "autoCreated": null,
              "choices": [
                "2025",
                "2024",
                "2019",
                "2018",
                "2017"
              ]
            }
          }
        }
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b975bc5ff2246d69c0556b839de514a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "2017",
              "2018",
              "2019",
              "2024",
              "2025"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Pick a competition year:",
            "description_tooltip": null,
            "disabled": false,
            "index": 2,
            "layout": "IPY_MODEL_9ff25a7170e045168e96940015e571b7",
            "style": "IPY_MODEL_77ecd564aa70409ca7db40953f03bc4b"
          }
        },
        "9ff25a7170e045168e96940015e571b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ecd564aa70409ca7db40953f03bc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0210ab83af564a22aea4bad3e7dda24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Bing Maps",
              "Google Maps",
              "OpenRouteService",
              "Azure Maps & OpenTopoData"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Pick an API Service for distance & elevations:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_86dfe68056b4498da1888947ef16543c",
            "style": "IPY_MODEL_de066c8b584d49cfbb0dd27138ec2986"
          }
        },
        "86dfe68056b4498da1888947ef16543c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de066c8b584d49cfbb0dd27138ec2986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}